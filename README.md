# TokenJoin

## Overview

TokenJoin is an efficient method for solving the Fuzzy Set Similarity Join problem. It relies only on tokens and their scores, called _utilities_, and avoids computing expensive intermediate similarity functions.

## Documentation

Javadoc is available [here]

## Usage

**Step 1**. Download or clone the project:
```sh
$ git clone https://github.com/alexZeakis/TokenJoin2.git
```

**Step 2**. Open terminal inside root folder and install by running:
```sh
$ mvn install
```
**Step 3**. Edit the parameters in the corresponding config file.

**Step 4** Run the executable:
```sh
$ java -jar target/tokenjoin-0.0.1-SNAPSHOT-jar-with-dependencies.jar --config <config_file> --similarity <similarity> --type <type> --mode <mode> --input <input_dir> --log <log_dir>
```

- Similarity values: ["jaccard", "edit"]
- Type values: ["threshold", "topk", "threshold_scalability", "threshold_verification", "threshold_threshold" ]
- Mode values: ["experiment"]
- Input directory: The directory of the datasets
- Log directory: the directory that the logs will be stored

The selected combination should be included in the corresponding config file.

## Experiment execution

There are 4 types of experiments conducted in TokenJoin.

- Comparing ThresholdJoin methods based on varying thresholds for 6 datasets. 
To reproduce the experiments mentioned in the paper, run:
```sh
$ ./execution/examples/bash/threshold_run.sh
```
This is a wrapper script for the 6 individual calls to the 6 datasets.

- Comparing ThresholdJoin methods based on varying sizes for 6 datasets.
To reproduce the experiments mentioned in the paper,  run:
```sh
$ ./execution/examples/bash/scalability_run.sh
```
This is a wrapper script for the 6 individual calls to the 6 datasets.

- Comparing Verification methods in ThresholdJoin for 6 datasets.
To reproduce the experiments mentioned in the paper, run:
```sh
$ ./execution/examples/bash/verification_run.sh
```
This is a wrapper script for the single call to Enron.

- Comparing TopkJoin methods based on varying ks for 6 datasets.
To reproduce the experiments mentioned in the paper, run:
```sh
$ ./execution/examples/bash/topk_run.sh
```
This is a wrapper script for the 6 individual calls to the 6 datasets.

Notice that in the `execution/examples/` we have smaller collection sizes and lighter JVM specifications. To run the original experimens, follow the same instructions but execute the corresponding scripts in `execution/experiments/`. Also notice that the existing logs inside `execution/experiments/` contain the original results and any new execution will be appended to the end of the file.

## Construction of plots

For each experiment a separate python script exists to analyse the results from the corresponding log file. The existing plots can be seen in `execution/experiments/plots/` and can be reproduced by running the following commands:

- Threshold - Threshold
```sh
$ python execution/python/Threshold.py execution/experiments/
```

- Threshold - Scalability
```sh
$ python execution/python/Scalability.py execution/experiments/
```

- Threshold - Verification
```sh
$ python execution/python/Verification.py execution/experiments/
```

- Topk 
```sh
$ python execution/python/Topk.py execution/experiments/
```



## Datasets.
We have used six real-world datasets:

- [Yelp](https://www.yelp.com/dataset): 160,016 sets extracted from the Yelp Open Dataset. Each set refers to a business. Its elements are the categories associated to it.

- [GDELT](https://www.gdeltproject.org/data.html): 500,000 randomly selected sets from January 2019 extracted from the GDELT Project. Each set refers to a news article. Its elements are the themes associated with it. Themes are hierarchical. Each theme is represented by a string concatenating all themes from it to the root of the hierarchy.

- [Enron](https://www.cs.cmu.edu/~enron): 517,431 sets, each corresponding to an email message. The elements are the words contained in the message body.

- [Flickr](https://yahooresearch.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images-for): 500,000 randomly selected images from the Flickr Creative Commons dataset. Each set corresponds to a photo. The elements are the tags associated to that photo.

- [DBLP](https://dblp.uni-trier.de/xml): 500,000 publications from the DBLP computer science bibliography. Each set refers to a publication. The elements are author names and words in the title.

- [MIND](https://msnews.github.io): 123,130 articles from the MIcrosoft News Dataset. Each set corresponds to an article. The elements are the words in its abstract.

The preprocessed versions of the datasets used in the experiments can be found [here](https://drive.google.com/drive/folders/1u9ixJM25koPkHi8FJ0atrHL1WcE8dtLw?usp=sharing).



## License

The contents of this project are licensed under the [Apache License 2.0](https://github.com/SLIPO-EU/loci/blob/master/LICENSE).

## Acknowledgement

This software is being developed in the context of the [SmartDataLake](https://smartdatalake.eu/) project. This project has received funding from the European Unionâ€™s [Horizon 2020 research and innovation programme](https://ec.europa.eu/programmes/horizon2020/en) under grant agreement No 825041.

